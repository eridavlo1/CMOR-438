{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0c0701",
   "metadata": {},
   "source": [
    "# Linear Regression Example\n",
    "Here demonstrates the three core fitting methods of the `LinearRegression` model: OLS, Ridge, and Gradient Descent (GD), using a single synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfc768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression \n",
    "from rice_ml.supervised_learning.linear_regression import LinearRegression\n",
    "from rice_ml.processing.post_processing import r2_score\n",
    "from rice_ml.processing.preprocessing import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf21d3",
   "metadata": {},
   "source": [
    "## 1. Load Data and Preparation\n",
    "Generate a synthetic dataset suitable for regression, adding noise to make the problem realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fae027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 100\n",
      "Number of Features: 5\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic regression data: 100 samples, 5 features\n",
    "X_raw, y = make_regression(\n",
    "    n_samples = 100, \n",
    "    n_features = 5, \n",
    "    n_informative = 3, # 3 features are useful for prediction\n",
    "    noise = 15.0, \n",
    "    random_state = 67\n",
    ")\n",
    "\n",
    "print(f\"Total Samples: {X_raw.shape[0]}\")\n",
    "print(f\"Number of Features: {X_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218fcf5",
   "metadata": {},
   "source": [
    "### 2. Data Pre-Processing: Scaling and Splitting\n",
    "While OLS and Ridge (closed-form solutions) do not strictly require scaling, Gradient Descent requires it for convergence. We standardize the features to ensure all methods can be compared fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a4b316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Size: 70 samples\n"
     ]
    }
   ],
   "source": [
    "# Standardization (Z-score scaling)\n",
    "X_mean = np.mean(X_raw, axis = 0)\n",
    "X_std = np.std(X_raw, axis = 0)\n",
    "X_scaled = (X_raw - X_mean) / X_std\n",
    "\n",
    "# Split the scaled dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size = 0.3, random_state = 67\n",
    ")\n",
    "\n",
    "# Verification\n",
    "print(f\"\\nTraining Set Size: {X_train.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4503fd",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation\n",
    "We train the model using all three modes: OLS, Ridge, and Gradient Descent.\n",
    "#### 3.1 Ordinary Least Squares (OLS- Closed Form)\n",
    "This model solves the Normal Equaton directly, giving the mathematically exact solution for unregularized linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce224c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning OLS Training (Closed-Form Solution)...\n",
      "Training Complete.\n",
      "OLS R^2 Score: 0.9728\n",
      "Intercept (b_): -8.10\n"
     ]
    }
   ],
   "source": [
    "# Initialize OLS model (method='ols')\n",
    "ols_model = LinearRegression(method='ols')\n",
    "\n",
    "print(\"Beginning OLS Training (Closed-Form Solution)...\")\n",
    "ols_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "r2_ols = ols_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "print(f\"OLS R^2 Score: {r2_ols:.4f}\")\n",
    "print(f\"Intercept (b_): {ols_model.b_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2b7c3",
   "metadata": {},
   "source": [
    "#### 4.2 Ridge Regression (Closed-Form with L2 Penalty)\n",
    "Ridge adds a regularization penalty (`alpha`) to stabilize the solution and reduce the magnitude of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e0e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning Ridge Training (Closed-Form with L2 Penalty, alpha=10.0)...\n",
      "Training Complete.\n",
      "Ridge R^2 Score: 0.9576\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge model (method='ridge', setting alpha)\n",
    "ridge_model = LinearRegression(method='ridge', alpha=10.0)\n",
    "\n",
    "print(\"\\nBeginning Ridge Training (Closed-Form with L2 Penalty, alpha=10.0)...\")\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "r2_ridge = ridge_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "print(f\"Ridge R^2 Score: {r2_ridge:.4f}\")\n",
    "# Note: Ridge coefficients should be slightly smaller than OLS coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224888c2",
   "metadata": {},
   "source": [
    "#### 4.3 Gradient Descent (GD - Iterative Solution)\n",
    "GD iteratively updates weights using the learning rate (`eta`) for a fixed number of iterations (`epochs`). This requires feature scaling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9097b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning GD Training (Iterative Solution, 1000 epochs)...\n",
      "Training Complete.\n",
      "GD R^2 Score: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# Initialize GD model (method='gd', setting optimization parameters)\n",
    "gd_model = LinearRegression(\n",
    "    method='gd', \n",
    "    eta=0.01, \n",
    "    epochs=1000, \n",
    "    random_state=67\n",
    ")\n",
    "\n",
    "print(\"\\nBeginning GD Training (Iterative Solution, 1000 epochs)...\")\n",
    "gd_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "r2_gd = gd_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "print(f\"GD R^2 Score: {r2_gd:.4f}\")\n",
    "\n",
    "# You can inspect the convergence path\n",
    "# print(f\"Final Cost: {gd_model.cost_history_[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd6a5b",
   "metadata": {},
   "source": [
    "### 4. Summary of Results\n",
    "| Method | Optimization Type | $R^2$ Score |\n",
    "| :--- | :--- | :--- |\n",
    "| **OLS (Ordinary Least Squares)** | Closed-form| 0.9728 |\n",
    "| **Ridge Regression** | Closed-form (Regularized) |0.9576 |\n",
    "| **GD (Gradient Descent)** | Iterative | 0.9728 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
