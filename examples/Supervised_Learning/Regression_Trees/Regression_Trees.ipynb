{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5762494d",
   "metadata": {},
   "source": [
    "# Regression Trees Example\n",
    "Here demonstrates the basic workflow for using the `DecisionTreeRegressor` for a continuous prediction task.\\\n",
    "Our objective is to train the regression tree using synthetic data and subsequently assess its effectiveness in continuous prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8400ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression \n",
    "from rice_ml.supervised_learning.regression_trees import DecisionTreeRegressor\n",
    "from rice_ml.processing.preprocessing import train_test_split\n",
    "from rice_ml.processing.post_processing import mse, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec36182",
   "metadata": {},
   "source": [
    "## 1. Load Data and Data Preparation\n",
    "Generate a synthetic dataset where the target variable is continuous, suitable for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cb7a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples in Dataset: 100\n",
      "Number of Features: 4\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic regression data (100 samples, 4 features)\n",
    "X, y = make_regression(\n",
    "    n_samples=100, \n",
    "    n_features=4, \n",
    "    n_informative=2, # Only 2 features are strongly correlated with y\n",
    "    noise=10.0, \n",
    "    random_state=67\n",
    ")\n",
    "\n",
    "print(f\"Total Samples in Dataset: {X.shape[0]}\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fad7f9",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing: Splitting the Dataset\n",
    "Separate the data into two distinct groups to ensure it's possible to evaluate the model's accuracy on unseen data: the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d996a5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Size (X_train): 80 samples\n",
      "Testing Set Size (X_test): 20 samples\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=67\n",
    ")\n",
    "\n",
    "# Verify the split integrity\n",
    "print(f\"\\nTraining Set Size (X_train): {X_train.shape[0]} samples\")\n",
    "print(f\"Testing Set Size (X_test): {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7f7a2",
   "metadata": {},
   "source": [
    "## 3. Initialize and Train the Model\n",
    "Instantiate the `DecisionTreeRegressor` and fit it using only the designated training data. Set a max_depth to prevent the tree from overfitting the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd7e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning Decision Tree Regressor Training...\n",
      "Training Complete. Tree structure learned.\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor(\n",
    "    max_depth=5,                 # Maximum depth to limit complexity\n",
    "    min_samples_split=5,         # Require at least 5 samples to split a node\n",
    "    random_state=67\n",
    ")\n",
    "\n",
    "print(\"\\nBeginning Decision Tree Regressor Training...\")\n",
    "\n",
    "# 2. Fit the model to the training data (X_train, y_train)\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Complete. Tree structure learned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd83dc",
   "metadata": {},
   "source": [
    "## 4. Prediction and Evaluation\n",
    "Use the trained tree structure to predict outcomes for the unseen test data and assess performance using standard regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8ac3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regression Results ---\n",
      "Mean Squared Error (MSE): 663.15\n",
      "R-squared (R2) Score: 0.7641\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate predictions on the held-out test set\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "# 2. Calculate Mean Squared Error (MSE)\n",
    "mean_squared_error = mse(y_test, y_pred)\n",
    "\n",
    "# 3. Calculate the R-squared (Coefficient of Determination) Score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Regression Results ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error:.2f}\")\n",
    "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "\n",
    "# Note: R^2 indicates the proportion of the variance in the dependent variable that is predictable from the independent variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
